{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxtBl6H5O4J74EgWBzkig0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/The-DarK-os/deep-learning/blob/master/Mnist_gans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "print(\"GPU Avail? \",tf.test.is_gpu_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZhkCyOVIfWz",
        "outputId": "9834cbd3-0379-48b0-9d94-02209ad8a9c5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n",
            "GPU Avail?  True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print(\"Found GPU at {}\".format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFY9KgXNI_4L",
        "outputId": "b4429e42-d52f-47b4-99f1-b916ab2ac842"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "wecWFXr0JfGk"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_generator(num_hidden_layer = 1,num_hidden_units=100,num_output_units=784):\n",
        "    model = tf.keras.models.Sequential()\n",
        "    for i in range(num_hidden_layer):\n",
        "      model.add(tf.keras.layers.Dense(units=num_hidden_units,use_bias=False))\n",
        "      model.add(tf.keras.layers.LeakyReLU())\n",
        "    model.add(tf.keras.layers.Dense(num_output_units,activation='tanh'))\n",
        "    return model\n",
        "\n",
        "def make_discriminator(num_hidden_layer=1,num_hidden_units=100,num_output_units=1):\n",
        "  model = tf.keras.models.Sequential()\n",
        "  for i in range(num_hidden_layer):\n",
        "    model.add(tf.keras.layers.Dense(units=num_hidden_units))\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "    model.add(tf.keras.layers.Dropout(rate=0.5))\n",
        "  model.add(tf.keras.layers.Dense(units=num_output_units,activation=None))\n",
        "  return model"
      ],
      "metadata": {
        "id": "u07OJcRIKiBL"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (28,28)\n",
        "z_size=20\n",
        "mode_z = 'uniform'\n",
        "gen_hidden_layers =1\n",
        "gen_hidden_size=100\n",
        "disc_hidden_layers=1\n",
        "disc_hidden_size=100\n",
        "tf.random.set_seed(1)\n",
        "gen_model = make_generator(num_hidden_layer=gen_hidden_layers,\n",
        "                           num_hidden_units=gen_hidden_size,\n",
        "                           num_output_units=np.prod(image_size))\n",
        "gen_model.build(input_shape=(None,z_size))\n",
        "gen_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpcHWhH1NSea",
        "outputId": "954b6481-1a40-4884-ec79-57c2db5ca8f0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 100)               2000      \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 100)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 784)               79184     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 81,184\n",
            "Trainable params: 81,184\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "disc_model = make_discriminator(num_hidden_layer=disc_hidden_layers,\n",
        "                                num_hidden_units=disc_hidden_size)\n",
        "disc_model.build(input_shape =(None,np.prod(image_size)))\n",
        "disc_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw9K4RjrOQ-b",
        "outputId": "cdf8b067-eee1-4c90-b592-91e67cc748de"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_7 (Dense)             (None, 100)               78500     \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 100)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 78,601\n",
            "Trainable params: 78,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_bldr = tfds.builder('mnist')\n",
        "mnist_bldr.download_and_prepare()\n",
        "mnist = mnist_bldr.as_dataset(shuffle_files=False)"
      ],
      "metadata": {
        "id": "C3pFYY9cSPIB"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(ex,mode='uniform'):\n",
        "  image = ex['image']\n",
        "  image = tf.image.convert_image_dtype(image,tf.float32) \n",
        "  image = tf.reshape(image,[-1]) \n",
        "  image = image*2 -1.\n",
        "  if mode =='uniform': \n",
        "    input_z = tf.random.uniform(shape=(z_size,),minval=-1.0,maxval=1.0)\n",
        "  else:\n",
        "    input_z = tf.random.normal(shape=(z_size,))\n",
        "  return input_z,image"
      ],
      "metadata": {
        "id": "Zary1wr7SpQI"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = mnist['train']\n",
        "mnist_train = mnist_train.map(preprocess)"
      ],
      "metadata": {
        "id": "2vBDjTjRTVhg"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = mnist_train.batch(32,drop_remainder=True)\n",
        "input_z,input_real = next(iter(mnist_train))"
      ],
      "metadata": {
        "id": "RtZNL_quThs4"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g_output = gen_model(input_z)"
      ],
      "metadata": {
        "id": "8R-OfM20UB74"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_logits_real = disc_model(input_real)"
      ],
      "metadata": {
        "id": "v7NzGdZCUJUw"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_logits_fake = disc_model(g_output)"
      ],
      "metadata": {
        "id": "qGjNIdNPUNqn"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "g_labels_real = tf.ones_like(d_logits_fake) \n",
        "g_loss = loss_fn(y_true=g_labels_real,y_pred = d_logits_fake) \n",
        "d_labels_real = tf.ones_like(d_logits_real)\n",
        "d_labels_fake = tf.zeros_like(d_logits_fake)\n",
        "d_loss_real = loss_fn(y_true = d_labels_real,y_pred = d_logits_real)\n",
        "d_loss_fake = loss_fn(y_true = d_labels_fake,y_pred = d_logits_fake)"
      ],
      "metadata": {
        "id": "WljGoTIAUSkQ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "num_epochs = 100\n",
        "batch_size = 64\n",
        "image_size = (28,28)\n",
        "z_size=10\n",
        "mode_z = 'uniform'\n",
        "gen_hidden_layers = 1\n",
        "gen_hidden_size = 100\n",
        "disc_hidden_layers = 1\n",
        "disc_hidden_size = 100"
      ],
      "metadata": {
        "id": "bAOxT5HcVnJ3"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(1)\n",
        "np.random.seed(1)\n",
        "\n",
        "fixed_z = tf.random.uniform(shape = (batch_size,z_size),minval=-1.,maxval=1.)"
      ],
      "metadata": {
        "id": "HtVzqX8iV_mv"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sample(g_model,z_input):\n",
        "  g_output = g_model(input_z,training=False)\n",
        "  images = tf.reshape(g_output,(batch_size*image_size))\n",
        "  return (images+1)*2."
      ],
      "metadata": {
        "id": "rZMVp5NYWRPn"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = mnist['train']\n",
        "mnist_train = mnist_train.map(lambda ex:preprocess(ex,mode=mode_z))"
      ],
      "metadata": {
        "id": "gGivfP4vWkh_"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = mnist_train.shuffle(10000)\n",
        "mnist_train = mnist_train.batch(batch_size,drop_remainder=True)"
      ],
      "metadata": {
        "id": "mMegxkYDWwmm"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device(device_name):\n",
        "  gen_model = make_generator(gen_hidden_layers,gen_hidden_size,np.prod(image_size))\n",
        "  gen_model.build(input_shape = (None,z_size))\n",
        "\n",
        "  disc_model = make_discriminator(disc_hidden_layers,disc_hidden_size)\n",
        "  disc_model.build(input_shape=(None,np.prod(image_size)))"
      ],
      "metadata": {
        "id": "dcHJeg-cXI4u"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.Adam()\n",
        "all_losses = []\n",
        "all_d_values = []\n",
        "epoch_samples = []\n",
        "\n",
        "start_time = time.time() \n",
        "for epoch in range(1,num_epochs+1):\n",
        "  epoch_losses , epoch_d_vals = [], []\n",
        "  for i , (input_z,input_real) in enumerate(mnist_train):\n",
        "    with tf.GradientTape() as g_tape:\n",
        "      g_out = gen_model(input_z)\n",
        "      g_log_fake = disc_model(g_out,training=True)\n",
        "      labels_real = tf.ones_like(d_logits_fake)\n",
        "      g_loss = loss_fn(y_true = labels_real,y_pred = d_logits_fake)\n",
        "    g_grads = g_tape.gradient(g_loss,gen_model.trainable_variables)\n",
        "    opt.apply_gradients(grads_and_vars = zip(g_grads,gen_model.trainable_variables))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yyi4Aui0X7v-",
        "outputId": "20c7f840-beaa-44d7-e6e2-d0b4cbffc6db"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-96e96c9318e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_real\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_logits_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mg_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgen_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_grads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgen_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    638\u001b[0m       \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcross\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mreplica\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \"\"\"\n\u001b[0;32m--> 640\u001b[0;31m     \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_empty_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/utils.py\u001b[0m in \u001b[0;36mfilter_empty_gradients\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     raise ValueError(f\"No gradients provided for any variable: {variable}. \"\n\u001b[0m\u001b[1;32m     74\u001b[0m                      f\"Provided `grads_and_vars` is {grads_and_vars}.\")\n\u001b[1;32m     75\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvars_with_empty_grads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable: (['dense_9/kernel:0', 'dense_10/kernel:0', 'dense_10/bias:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'dense_9/kernel:0' shape=(10, 100) dtype=float32, numpy=\narray([[ 1.53805256e-01,  6.26977980e-02,  6.87925518e-03,\n        -5.08760661e-02,  3.77896428e-02, -2.10903853e-01,\n        -1.50577843e-01,  9.56160128e-02, -3.77956033e-03,\n        -7.19134510e-02,  3.69510055e-03, -1.30005807e-01,\n         1.62810206e-01,  2.07433164e-01,  1.23278499e-02,\n        -5.50518185e-02, -1.02846175e-01, -2.17774197e-01,\n        -3.18063945e-02, -1.89560443e-01,  2.17272282e-01,\n         1.20027602e-01,  8.06926489e-02,  1.58445388e-02,\n        -8.24269801e-02, -4.76117879e-02, -1.41489953e-01,\n         1.52175605e-01, -1.62134647e-01,  4.78620231e-02,\n         7.31474161e-02,  2.03084677e-01,  2.19271660e-01,\n        -6.24886155e-03, -4.64410633e-02,  9.03428197e-02,\n         8.24816227e-02, -4.50473279e-02, -2.25959986e-01,\n        -8.81177187e-03,  1.78848505e-01, -8.63753259e-03,\n         5.24558127e-03,  4.10106778e-02,  2.20636159e-01,\n         8.48720074e-02,  1.65890455e-01, -2.30484530e-01,\n        -3.18943113e-02, -2.05426857e-01, -5.51655740e-02,\n         1.05354577e-01, -8.63480568e-03,  2.08220482e-02,\n        -2.16693401e-01, -1.78942382e-01,  1.48741812e-01,\n         1.69146091e-01,  2.23775387e-01, -4.09054905e-02,\n         6.19744956e-02,  8.98095369e-02,  4.17324901e-03,\n        -7.88213164e-02, -3.54820043e-02, -9.55605060e-02,\n        -2.42467076e-02,  1.92675442e-01, -8.38027894e-02,\n        -1.96126923e-01,  2.25410342e-01, -2.06106633e-01,\n         1.01914614e-01, -6.27047718e-02, -1.90215215e-01,\n        -6.59391284e-04, -1.26624033e-01,  3.66634130e-02,\n         2.07465053e-01, -4.19400632e-02,  1.35301620e-01,\n        -1.73941091e-01,  1.41097397e-01,  1.05710387e-01,\n        -1.81614593e-01,  1.96475267e-01,  1.28800720e-01,\n        -1.83640569e-02, -2.04996601e-01, -6.37477636e-02,\n         8.09772313e-02, -1.67426467e-03, -1.41262710e-01,\n         1.10159636e-01,  9.93838906e-02,  5.29395044e-02,\n        -1.08326465e-01, -1.32942051e-01,  1.09381020e-01,\n         1.99835718e-01],\n       [-9.68513936e-02,  8.78495872e-02,  1.12012178e-02,\n        -1.62240565e-01,  1.66398764e-01,  2.21170068e-01,\n         8.07984769e-02, -1.52538314e-01, -3.27876210e-03,\n         1.40155256e-02, -2.07774386e-01, -1.36824071e-01,\n         1.27098769e-01, -2.04309195e-01, -1.40108243e-01,\n        -1.54045925e-01, -4.08823788e-02,  6.48418069e-03,\n        -2.14106604e-01, -1.61633179e-01,  1.88487619e-01,\n        -2.82289535e-02, -1.42483443e-01, -1.07083172e-02,\n        -1.72913685e-01, -1.53172255e-01,  2.09847212e-01,\n        -8.63246620e-03,  2.01111406e-01,  1.21306121e-01,\n        -9.23427790e-02,  1.89864814e-01, -6.51487410e-02,\n         2.07212865e-01,  1.45399243e-01,  1.32299811e-01,\n        -1.44173741e-01, -2.03801379e-01, -1.01966053e-01,\n        -4.66832817e-02,  1.57949775e-01,  8.56334567e-02,\n         3.87097001e-02, -5.33165187e-02,  1.57586277e-01,\n        -7.55691230e-02, -1.66130602e-01,  1.54677689e-01,\n         2.20220566e-01,  1.92712367e-01, -1.04140297e-01,\n         1.11144274e-01,  1.91563845e-01,  1.35442197e-01,\n        -9.25903916e-02, -1.45080090e-01, -6.67514503e-02,\n        -2.22246617e-01,  2.11204767e-01, -3.83728743e-02,\n         1.73699051e-01, -3.55741531e-02,  4.61183190e-02,\n         1.67906642e-01,  2.32195526e-01, -5.01398891e-02,\n         1.63738936e-01,  7.12001920e-02,  3.08404565e-02,\n        -1.78329885e-01,  1.12496763e-01,  1.33146018e-01,\n         3.84655595e-03, -2.20244110e-01,  6.73682392e-02,\n         2.29522586e-02, -5.11769652e-02, -1.01068616e-01,\n         1.28260761e-01,  1.87709540e-01, -1.60213947e-01,\n        -7.91103691e-02, -1.05217084e-01, -2.17468888e-02,\n         2.15459645e-01, -1.19122922e-01, -1.95422471e-02,\n         1.63713872e-01, -2.67744660e-02,  1.42062306e-01,\n         1.72216386e-01, -5.92978299e-02,  8.89468193e-03,\n        -2.23632902e-01,  9.07253623e-02,  1.76244855e-01,\n        -1.71325684e-01,  5.72201014e-02,  2.18769312e-01,\n         1.10550016e-01],\n       [-1.91183597e-01, -9.97675508e-02, -2.08280265e-01,\n         2.29826510e-01,  1.37536079e-01, -1.70197725e-01,\n         2.68337727e-02,  2.16189533e-01, -1.16183326e-01,\n        -6.34360462e-02, -1.85772911e-01,  1.89158022e-01,\n        -1.58585161e-01, -2.45324075e-02,  2.16327518e-01,\n         2.05440223e-02, -3.35640162e-02,  2.19261140e-01,\n         5.79001009e-02,  1.37722582e-01,  2.20457435e-01,\n        -1.40774980e-01,  1.87785774e-01,  1.12630725e-01,\n        -1.66649625e-01, -3.25544327e-02, -2.03159630e-01,\n         1.50098741e-01,  1.13662690e-01,  1.10932738e-01,\n        -1.89938411e-01, -1.53303236e-01,  2.06014037e-01,\n         1.71496332e-01, -1.58724263e-01,  2.76329219e-02,\n        -6.02651536e-02, -1.23167701e-01,  1.77540809e-01,\n        -1.32763088e-01, -2.68706828e-02,  2.27576166e-01,\n         7.75888562e-04, -1.25874996e-01,  2.05340892e-01,\n         2.19948113e-01,  7.31915832e-02, -1.35368198e-01,\n         9.30797756e-02, -2.05911398e-02, -1.09572023e-01,\n         1.73458159e-01,  5.12936413e-02, -2.05001563e-01,\n         2.19020486e-01,  2.16190457e-01,  1.30487800e-01,\n        -1.76451147e-01, -1.64532959e-01,  1.44342065e-01,\n        -1.89230531e-01,  9.32937860e-02,  1.08919144e-01,\n        -1.87593684e-01, -1.87672406e-01, -2.12130487e-01,\n         1.18035972e-02, -2.26087496e-01,  1.60106152e-01,\n        -5.92735410e-03,  2.18547851e-01, -1.86249390e-01,\n        -9.34420526e-03,  1.84372097e-01, -3.62603813e-02,\n         8.03655088e-02, -2.07667857e-01,  5.42424619e-02,\n        -2.14806259e-01, -4.08479571e-02, -2.13979930e-01,\n        -9.68345255e-02,  1.58925354e-02, -8.60477388e-02,\n         1.46086484e-01,  1.06983125e-01,  1.71626598e-01,\n        -1.63238063e-01, -3.96445543e-02,  4.81835902e-02,\n        -2.23090827e-01, -1.13334663e-01, -1.98120639e-01,\n         1.43079281e-01, -1.78113878e-01, -6.76874220e-02,\n         6.40683770e-02, -2.01693118e-01, -2.21437991e-01,\n         2.03553259e-01],\n       [-1.31360292e-02,  1.16693497e-01,  1.24551088e-01,\n         2.87386179e-02,  5.36794066e-02, -8.92272145e-02,\n         1.90388501e-01,  3.41591537e-02,  1.90596461e-01,\n         5.16240895e-02,  1.99131280e-01, -7.74001330e-02,\n         1.76892579e-02,  8.68707299e-02, -8.27478766e-02,\n        -8.45341831e-02, -8.09506178e-02,  1.10529304e-01,\n        -1.99972868e-01, -5.87686747e-02, -1.23845525e-01,\n        -1.37565613e-01,  1.44764185e-02, -9.35100466e-02,\n         4.00618911e-02, -1.31438524e-01, -1.04126766e-01,\n         4.90307808e-03,  9.65760350e-02, -2.12924972e-01,\n         5.52009940e-02,  2.01035887e-01, -7.57040381e-02,\n         1.00264847e-01,  8.38987231e-02,  2.24620104e-04,\n        -1.26530051e-01,  9.38406289e-02, -2.17154890e-01,\n        -1.87833443e-01, -2.00353682e-01, -5.94743490e-02,\n         1.72170728e-01, -2.04890639e-01,  9.62562561e-02,\n         4.32525575e-03, -1.29311711e-01,  9.98337567e-02,\n         1.46953255e-01,  1.07061237e-01, -1.90272331e-02,\n         6.24741614e-03, -9.38595682e-02,  9.54830050e-02,\n        -1.91188097e-01,  1.06780380e-01, -1.28893659e-01,\n        -2.35848576e-02,  2.11544335e-03,  1.64843202e-02,\n        -6.09482080e-02, -1.11543909e-01, -2.11804360e-01,\n         2.32933849e-01,  2.31774300e-01, -2.34124064e-02,\n        -1.02280825e-01, -1.32754967e-01, -2.28992626e-01,\n         1.37376398e-01, -1.35479957e-01, -7.97367394e-02,\n        -4.50386405e-02, -3.23818177e-02, -1.27651602e-01,\n         5.33901453e-02, -6.20654225e-02, -1.18417367e-01,\n         1.25875324e-01,  1.62316471e-01,  2.70912051e-02,\n         1.25087976e-01, -1.25978053e-01, -2.24508226e-01,\n        -1.00891337e-01,  1.42434984e-02,  3.99280190e-02,\n         1.16886050e-01, -1.31550163e-01, -1.91420138e-01,\n        -5.44483215e-02,  1.97262406e-01, -1.23338535e-01,\n        -1.83300614e-01, -1.25259921e-01, -9.18882340e-02,\n        -1.06396839e-01, -2.09362000e-01,  7.29058087e-02,\n         5.75327575e-02],\n       [ 7.57941306e-02,  7.74202347e-02, -3.46584618e-02,\n        -1.20490037e-01,  1.98565930e-01,  8.00007880e-02,\n        -9.47524309e-02,  1.77070349e-01,  1.76937699e-01,\n         2.20435649e-01,  9.99161005e-02, -1.26681387e-01,\n         1.50635630e-01,  1.34409726e-01,  1.85933769e-01,\n        -2.18114525e-01, -6.53010309e-02,  1.21322215e-01,\n        -1.00262672e-01,  1.46792978e-01,  2.18610495e-01,\n        -6.23346418e-02,  2.19477415e-01, -1.51303828e-01,\n         9.54878330e-02, -8.91049355e-02,  1.09828651e-01,\n        -1.10678770e-01, -1.31046399e-01,  1.45255357e-01,\n        -7.65492469e-02, -6.32963926e-02, -1.51577517e-01,\n        -4.82710153e-02,  2.29556859e-01, -1.18879810e-01,\n        -5.45505583e-02,  1.51963830e-02,  5.74815869e-02,\n        -2.30147585e-01,  1.11109644e-01,  7.01194704e-02,\n        -7.89295584e-02, -4.96374667e-02, -9.52333659e-02,\n        -1.67896077e-01,  3.16241384e-02,  1.83038563e-01,\n         1.17002428e-02,  2.25384831e-02, -1.67241916e-01,\n        -9.59880352e-02, -1.36665717e-01,  8.15242529e-04,\n        -1.13472417e-01,  2.11391240e-01,  1.64014101e-02,\n         6.21167123e-02,  2.27462977e-01, -1.86157018e-01,\n        -1.34924412e-01,  7.26099908e-02,  2.27019191e-04,\n        -1.38590947e-01, -9.85995978e-02,  3.05714607e-02,\n         7.09426105e-02,  1.35215461e-01,  1.55243874e-01,\n        -1.71867579e-01, -2.19182670e-03,  1.98128164e-01,\n        -1.61324248e-01, -2.02645794e-01, -1.29294351e-01,\n         2.11492032e-01,  6.96617961e-02,  6.46558404e-03,\n        -2.10718274e-01,  1.82482839e-01,  2.04632550e-01,\n         9.02615190e-02,  4.03105617e-02,  8.70289207e-02,\n         5.99738657e-02, -2.05581829e-01, -1.46685243e-02,\n        -5.04851788e-02,  2.27636486e-01, -1.30756915e-01,\n         8.99541378e-03, -1.86690837e-02,  1.09680653e-01,\n         1.75803214e-01, -1.67209893e-01,  2.12101191e-01,\n        -3.62543762e-02, -6.47036135e-02, -2.17327341e-01,\n         8.68609250e-02],\n       [ 1.56438559e-01, -2.01435685e-02, -1.28815204e-01,\n         1.94817036e-01,  2.13683963e-01,  1.18007720e-01,\n        -3.32633853e-02,  1.96175277e-03,  9.86002088e-02,\n        -1.45240277e-01, -1.22354351e-01,  1.25783503e-01,\n         2.27580070e-01, -4.70885336e-02,  1.00371689e-02,\n         1.53848588e-01, -1.22884393e-01, -1.75002679e-01,\n         1.82568669e-01, -1.91504493e-01,  7.10465014e-03,\n         1.44823343e-01,  6.66816235e-02, -2.13281170e-01,\n         1.03132457e-01, -4.55071479e-02,  1.82034940e-01,\n         6.62778020e-02, -2.74118632e-02, -2.28029087e-01,\n        -4.91623729e-02,  5.92894852e-02, -5.68953454e-02,\n         5.03799319e-03, -1.96447045e-01, -1.74537569e-01,\n        -2.09474817e-01, -3.17161381e-02, -1.39566720e-01,\n         2.38124430e-02, -1.95811093e-01,  1.95050299e-01,\n         2.55454481e-02, -6.68694973e-02,  7.47904480e-02,\n         3.54562104e-02,  1.62829518e-01,  9.55173969e-02,\n         2.62833536e-02,  2.29514658e-01,  8.01430643e-02,\n        -1.29488736e-01,  4.42610383e-02,  2.84020007e-02,\n         6.46934211e-02,  1.28104419e-01,  2.11170256e-01,\n        -8.51977468e-02, -1.05269700e-01, -2.22620860e-01,\n        -1.33830920e-01,  1.47201300e-01, -2.08164826e-01,\n         8.14109445e-02, -1.95605844e-01,  2.15288132e-01,\n        -1.76551044e-01,  8.83300006e-02,  1.77979022e-01,\n        -1.21130943e-01, -1.82873413e-01,  1.23572499e-02,\n        -1.80476218e-01, -1.92882463e-01,  1.51282161e-01,\n        -1.13654166e-01, -2.01763555e-01,  6.22921586e-02,\n         3.69924605e-02,  7.71050751e-02, -3.51725221e-02,\n         2.12926298e-01,  1.17496550e-01, -1.06457323e-02,\n         3.64038944e-02,  1.15508854e-01, -1.61970839e-01,\n        -5.32224774e-02, -8.49876106e-02, -1.78832799e-01,\n        -1.18324541e-01, -1.39148057e-01, -1.77131861e-01,\n        -1.04870185e-01, -1.68000042e-01, -6.07953966e-03,\n        -6.25937432e-02,  1.01685852e-01, -8.16814005e-02,\n         3.28903794e-02],\n       [ 1.13901913e-01, -1.10791579e-01,  1.10526204e-01,\n        -9.87693816e-02, -1.73759669e-01, -2.18238249e-01,\n         2.19749510e-02, -6.21544570e-02, -2.08410218e-01,\n        -1.08187869e-01, -4.28527594e-02,  1.70453072e-01,\n        -7.03916997e-02,  1.07738793e-01,  1.00521028e-01,\n        -5.88331670e-02, -1.35232389e-01, -1.43984467e-01,\n         2.31435537e-01,  1.69967711e-02, -1.21981941e-01,\n         2.24987209e-01, -1.58314377e-01,  1.87031001e-01,\n        -1.42722979e-01, -2.17973590e-01, -1.27715245e-01,\n        -1.46435797e-02, -9.07330960e-02,  1.66040123e-01,\n         1.58885866e-01,  1.41140103e-01,  7.21968114e-02,\n        -2.85384059e-03, -1.84162736e-01,  1.89530611e-01,\n         1.35713220e-01,  2.24274009e-01,  1.88649148e-01,\n        -2.01918572e-01, -1.18115515e-01,  7.16662407e-03,\n        -4.82858270e-02, -2.27826461e-01,  9.25804377e-02,\n         8.51413012e-02,  6.43714070e-02,  1.63668215e-01,\n         2.01451361e-01, -1.02500498e-01, -9.46573317e-02,\n        -1.43238157e-01,  1.12398535e-01, -1.58927947e-01,\n         1.11081630e-01, -4.78757769e-02,  1.49260461e-01,\n         1.67804956e-02, -1.91371858e-01,  9.54308212e-02,\n         1.89294517e-01, -8.98058116e-02, -8.80196691e-03,\n        -9.41992253e-02, -1.60459399e-01,  1.85631990e-01,\n         4.13956046e-02, -1.59814149e-01, -5.07014990e-02,\n        -1.32108092e-01,  6.19301796e-02, -2.06316501e-01,\n        -2.00511038e-01, -3.87535244e-02, -6.75910860e-02,\n        -4.54327017e-02,  6.36444092e-02, -9.90509987e-03,\n         5.59053123e-02, -1.39287084e-01, -1.02118567e-01,\n         7.75672793e-02,  1.25557601e-01,  7.97170699e-02,\n        -2.16243088e-01,  4.54932451e-03,  1.13739371e-01,\n        -7.03063905e-02, -1.81051373e-01,  1.27334863e-01,\n        -4.20841128e-02, -2.24391073e-01, -2.78275907e-02,\n         2.29877144e-01, -1.62802726e-01, -8.22923928e-02,\n         3.62643301e-02,  5.95214069e-02,  2.27226138e-01,\n         1.17328048e-01],\n       [-6.98075294e-02, -1.78455725e-01, -1.34102985e-01,\n        -7.15822428e-02,  1.30968899e-01, -8.71081650e-02,\n        -7.80909806e-02,  1.81213230e-01, -1.35507971e-01,\n        -1.54005766e-01, -2.28689045e-01, -1.53516769e-01,\n         1.16787523e-01, -1.49037495e-01, -3.65396887e-02,\n        -1.58351526e-01, -1.38724744e-01, -7.28517771e-03,\n        -1.15968667e-01,  6.71356022e-02,  2.20685214e-01,\n        -2.10488960e-01, -1.00577384e-01, -1.14655562e-01,\n        -1.49610251e-01, -1.99720070e-01, -1.50396988e-01,\n        -1.16896898e-01, -3.86046767e-02, -7.39304870e-02,\n        -1.37983382e-01, -2.16484964e-02, -1.65453941e-01,\n         1.90961301e-01,  1.35261506e-01,  1.79637849e-01,\n         2.13886499e-01, -4.89313006e-02, -1.26789302e-01,\n        -1.79300815e-01,  6.76755607e-02,  8.73885751e-02,\n        -1.30384713e-02, -8.00089091e-02,  1.83516920e-01,\n        -3.39137614e-02,  2.00834930e-01,  1.75078809e-01,\n         1.54303968e-01, -2.33510599e-01,  2.16146469e-01,\n        -1.98463306e-01, -3.84795666e-02, -5.48628867e-02,\n         9.57633555e-02, -2.28969842e-01,  3.86903286e-02,\n        -7.84268528e-02, -1.28531098e-01, -1.05423942e-01,\n        -2.21312642e-02,  7.41840601e-02, -3.74906957e-02,\n        -9.65473056e-02,  8.81392360e-02, -1.14510901e-01,\n        -1.77371189e-01, -6.08834475e-02, -1.19770899e-01,\n        -1.88991129e-02, -1.22042745e-01, -6.14845455e-02,\n         3.68156433e-02, -1.35114789e-01,  4.00935709e-02,\n        -8.35942626e-02,  5.80042601e-02, -1.39151722e-01,\n         1.41581297e-02,  1.93199307e-01, -2.27439359e-01,\n        -9.59191024e-02,  2.49475241e-02,  1.84605926e-01,\n        -2.12419927e-01, -8.11056942e-02, -1.36660263e-01,\n        -1.29710138e-01, -1.08397961e-01, -1.20548449e-01,\n         6.15251958e-02, -2.07324579e-01, -1.51638091e-02,\n        -1.46108031e-01, -1.23965360e-01, -8.17391425e-02,\n        -1.76485121e-01, -1.83437809e-01,  2.38262415e-02,\n        -1.14007533e-01],\n       [-1.42803386e-01,  1.20435148e-01,  2.99617946e-02,\n         3.52152288e-02,  9.63636637e-02, -1.20612204e-01,\n         1.07745230e-01, -1.78137496e-01,  1.25237495e-01,\n         1.52856886e-01,  1.78878307e-01, -8.45851302e-02,\n        -7.00747520e-02, -9.85165834e-02,  6.12837970e-02,\n         1.98936999e-01, -2.31942579e-01, -1.82803690e-01,\n         6.23760819e-02,  4.24771905e-02, -1.84323773e-01,\n        -2.17783660e-01,  4.43484485e-02,  5.48221767e-02,\n         7.78298080e-03,  6.86237812e-02,  5.55679202e-03,\n         4.92035151e-02, -9.18454677e-02,  1.30471855e-01,\n        -2.33109459e-01, -2.22948775e-01,  1.13187045e-01,\n        -8.73513818e-02,  3.01085114e-02, -1.42607987e-01,\n        -1.09850436e-01,  1.54882729e-01, -1.75522298e-01,\n        -6.90261871e-02, -1.21102214e-01, -2.10670769e-01,\n        -1.19608529e-01, -6.72508627e-02, -1.46571547e-01,\n        -4.42321301e-02, -1.71960071e-01,  1.54598087e-01,\n         1.88970774e-01, -2.13037103e-01,  1.84377670e-01,\n         2.01097161e-01,  1.34844273e-01, -6.14559203e-02,\n         1.53349400e-01, -4.60304469e-02, -8.63209218e-02,\n         8.74149799e-03,  1.37243539e-01,  2.09184319e-01,\n        -5.51274866e-02,  1.43273234e-01, -7.02573359e-02,\n         1.00652963e-01,  1.11962646e-01, -1.46655291e-01,\n         9.77452099e-02, -1.88250959e-01,  1.80844456e-01,\n        -9.40467715e-02, -1.90060809e-01,  1.19578838e-01,\n         1.24592125e-01,  3.48759592e-02, -1.55991077e-01,\n         1.55492008e-01,  6.80055320e-02,  5.91997206e-02,\n         1.04606420e-01, -2.26129144e-02,  8.79893303e-02,\n        -2.76345909e-02,  5.89520335e-02, -1.17920570e-01,\n        -7.49118477e-02,  1.20491713e-01,  2.14148939e-01,\n        -1.80038884e-01, -2.22395077e-01, -1.71696469e-01,\n        -1.37308627e-01,  4.07271981e-02, -1.80446371e-01,\n        -8.48151594e-02, -7.51865208e-02, -1.91075340e-01,\n        -1.42062485e-01, -1.04544997e-01,  2.05053568e-01,\n         1.67426407e-01],\n       [ 7.99063444e-02,  5.97211421e-02,  2.03751922e-02,\n         6.60801828e-02, -1.54289156e-01, -1.39525577e-01,\n         3.06152403e-02,  1.21095091e-01, -1.50948748e-01,\n         1.54771477e-01, -1.01673722e-01,  2.25714475e-01,\n        -5.01803160e-02,  1.77180201e-01,  2.39433944e-02,\n         1.58445239e-01,  6.54665828e-02, -1.41871095e-01,\n         2.19430238e-01,  1.40832514e-01, -2.11897343e-01,\n         1.92500651e-01,  2.09112257e-01,  1.60801232e-01,\n         8.81101191e-02,  1.88041210e-01, -1.64096072e-01,\n        -4.26930636e-02,  2.31157839e-02, -1.80110052e-01,\n         1.40670300e-01, -5.30387461e-03, -2.30183065e-01,\n        -2.00516433e-01,  8.32540989e-02, -5.58139384e-03,\n         6.20658100e-02,  1.11417234e-01,  9.78559554e-02,\n        -2.01986238e-01,  1.91215217e-01, -2.10388303e-02,\n         1.24413282e-01,  1.46069229e-01,  9.79486108e-02,\n        -1.09693855e-01, -1.33493155e-01, -4.12169695e-02,\n        -1.78115502e-01, -1.74697250e-01, -6.90997988e-02,\n        -1.81071132e-01,  2.23290920e-02, -5.28391004e-02,\n        -3.12089175e-02, -1.02756247e-01, -1.64977968e-01,\n         1.55754983e-01, -8.14782679e-02,  1.83432251e-01,\n        -2.15537146e-01, -6.74096197e-02, -8.96430612e-02,\n         5.73564172e-02,  1.74583554e-01, -1.15346909e-03,\n         1.39132172e-01, -1.35093182e-02,  1.36218756e-01,\n         2.32309401e-01, -1.29682735e-01, -2.19742805e-01,\n         5.07995486e-02, -2.19820365e-01, -8.95311385e-02,\n         2.30455965e-01,  1.07180446e-01, -1.13483056e-01,\n        -3.41393799e-02,  1.69559211e-01,  1.16328776e-01,\n         2.98199654e-02,  1.84751302e-01, -5.64040691e-02,\n         8.29361975e-02,  4.17375565e-02, -4.10320461e-02,\n        -1.15208320e-01,  1.44472301e-01,  5.33390045e-02,\n        -1.80086330e-01, -1.21314526e-02, -1.07259139e-01,\n        -2.18536764e-01, -6.09469265e-02, -1.79850399e-01,\n         1.14939809e-01, -1.15819938e-01,  2.15749234e-01,\n         2.13717818e-01]], dtype=float32)>), (None, <tf.Variable 'dense_10/kernel:0' shape=(100, 784) dtype=float32, numpy=\narray([[-0.04342492, -0.04304245,  0.00059832, ..., -0.07712958,\n         0.07686278, -0.05612057],\n       [ 0.01149441,  0.05208384,  0.01233798, ...,  0.04260407,\n         0.03162013,  0.07897134],\n       [-0.0203205 , -0.07208054,  0.06209275, ...,  0.0376362 ,\n         0.04650404,  0.06172301],\n       ...,\n       [-0.04873564, -0.05293531,  0.07231329, ..., -0.00319453,\n         0.01302192,  0.01438393],\n       [-0.05697046, -0.03232313,  0.01584405, ...,  0.00220684,\n         0.0792069 ,  0.06224535],\n       [-0.0748025 ,  0.03456381, -0.05902725, ..., -0.03165814,\n         0.07240334,  0.02061138]], dtype=float32)>), (None, <tf.Variable 'dense_10/bias:0' shape=(784,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>))."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vVf8rpxxZ7oO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}